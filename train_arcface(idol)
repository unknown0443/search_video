{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10974639,"sourceType":"datasetVersion","datasetId":6829025},{"sourceId":10978590,"sourceType":"datasetVersion","datasetId":6831865},{"sourceId":10986652,"sourceType":"datasetVersion","datasetId":6838065},{"sourceId":10991331,"sourceType":"datasetVersion","datasetId":6841298}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q insightface onnxruntime torch torchvision albumentations tqdm scikit-learn numpy opencv-python\n\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nimport numpy as np\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom tqdm import tqdm\nfrom insightface.app import FaceAnalysis\nimport albumentations as A\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T01:47:33.372842Z","iopub.execute_input":"2025-03-12T01:47:33.373143Z","iopub.status.idle":"2025-03-12T01:47:39.583751Z","shell.execute_reply.started":"2025-03-12T01:47:33.373122Z","shell.execute_reply":"2025-03-12T01:47:39.582805Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# âœ… ë°ì´í„° ê²½ë¡œ ì„¤ì •\nDATASET_DIR = \"/kaggle/input/test-imgidol/\"\nUNKNOWN_DIR = \"/kaggle/input/unknown/\"  # ğŸ”¥ Unknown ë°ì´í„° ê²½ë¡œ ì¶”ê°€","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T01:47:39.585011Z","iopub.execute_input":"2025-03-12T01:47:39.585411Z","iopub.status.idle":"2025-03-12T01:47:39.589105Z","shell.execute_reply.started":"2025-03-12T01:47:39.585383Z","shell.execute_reply":"2025-03-12T01:47:39.588445Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# âœ… ê·¸ë£¹ ë° ë©¤ë²„ ì„¤ì • (Unknown í¬í•¨)\nGROUPS = {\n    \"EXO\": {\"dio\": \"D.O\", \"kai\": \"Kai\"},\n    \"IVE\": {\"an\": \"An Yujin\", \"jang\": \"Jang Wonyoung\"},\n    \"NJZ\": {\"dani\": \"Danielle\", \"harin\": \"Gang Harin\", \"minji\": \"Kim Minji\", \"pham\": \"Pham Hanni\"},\n    \"RED\": {\"irene\": \"Irene\", \"joy\": \"Joy\", \"seulgi\": \"Seulgi\", \"wendy\": \"Wendy\"},\n    \"SK\": {\"hyun\": \"Hyunjin\", \"pil\": \"Felix\"},\n    \"UNKNOWN\": {\"unknown\": \"Unknown\"}  # ğŸ”¥ Unknown í´ë˜ìŠ¤ ì¶”ê°€\n}\n\ngroup_mapping = {group: i for i, group in enumerate(GROUPS.keys())}\nmember_mapping = {}\nfor group, members in GROUPS.items():\n    for j, (folder_name, full_name) in enumerate(members.items()):\n        member_mapping[full_name] = j  # ê° ê·¸ë£¹ ë‚´ì—ì„œ 0ë¶€í„° ì‹œì‘","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T01:47:39.590617Z","iopub.execute_input":"2025-03-12T01:47:39.590837Z","iopub.status.idle":"2025-03-12T01:47:39.602975Z","shell.execute_reply.started":"2025-03-12T01:47:39.590819Z","shell.execute_reply":"2025-03-12T01:47:39.602263Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# âœ… ArcFace ëª¨ë¸ ë¡œë“œ\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\napp = FaceAnalysis(name=\"buffalo_l\", providers=[\"CUDAExecutionProvider\", \"CPUExecutionProvider\"])\napp.prepare(ctx_id=0 if torch.cuda.is_available() else -1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T01:47:39.604050Z","iopub.execute_input":"2025-03-12T01:47:39.604315Z","iopub.status.idle":"2025-03-12T01:47:41.326909Z","shell.execute_reply.started":"2025-03-12T01:47:39.604283Z","shell.execute_reply":"2025-03-12T01:47:41.326176Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:118: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\nfind model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\nApplied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\nfind model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\nApplied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\nfind model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\nApplied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\nfind model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\nApplied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\nfind model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\nset det-size: (640, 640)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# âœ… ì–¼êµ´ í¬ë¡­ í•¨ìˆ˜ (1.5ë°° í™•ëŒ€ í›„ ì‚¬ìš©)\ndef crop_face(image, bbox, scale=1.5):\n    \"\"\"\n    ì–¼êµ´ì„ ì¼ì • ë¹„ìœ¨ (1.5ë°°) í™•ëŒ€í•˜ì—¬ í¬ë¡­í•˜ëŠ” í•¨ìˆ˜\n    \"\"\"\n    x1, y1, x2, y2 = bbox\n    cx, cy = (x1 + x2) // 2, (y1 + y2) // 2  # ì¤‘ì‹¬ì \n    w, h = int((x2 - x1) * scale), int((y2 - y1) * scale)  # í™•ëŒ€ëœ í¬ê¸°\n\n    new_x1, new_y1 = max(0, cx - w // 2), max(0, cy - h // 2)\n    new_x2, new_y2 = min(image.shape[1], cx + w // 2), min(image.shape[0], cy + h // 2)\n\n    cropped_face = image[new_y1:new_y2, new_x1:new_x2]\n    return cropped_face","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T01:47:41.327901Z","iopub.execute_input":"2025-03-12T01:47:41.328125Z","iopub.status.idle":"2025-03-12T01:47:41.333601Z","shell.execute_reply.started":"2025-03-12T01:47:41.328107Z","shell.execute_reply":"2025-03-12T01:47:41.332557Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# âœ… ë°ì´í„°ì…‹ í´ë˜ìŠ¤ (ì–¼êµ´ í¬ë¡­ + Unknown ì¶”ê°€)\nclass FaceDataset(Dataset):\n    def __init__(self, image_dirs, transform=None):\n        self.image_paths = []\n        self.labels = []\n\n        # âœ… ê¸°ì¡´ ê·¸ë£¹ ë°ì´í„° ì¶”ê°€\n        for group, members in GROUPS.items():\n            for folder_name, full_name in members.items():\n                image_folder = os.path.join(DATASET_DIR, group, folder_name)\n                if not os.path.exists(image_folder):\n                    continue\n                for img in os.listdir(image_folder):\n                    self.image_paths.append(os.path.join(image_folder, img))\n                    self.labels.append((group_mapping[group], member_mapping[full_name]))\n\n        # âœ… Unknown ë°ì´í„° ì¶”ê°€\n        if os.path.exists(UNKNOWN_DIR):\n            for img in os.listdir(UNKNOWN_DIR):\n                self.image_paths.append(os.path.join(UNKNOWN_DIR, img))\n                self.labels.append((group_mapping[\"UNKNOWN\"], member_mapping[\"Unknown\"]))\n\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        faces = app.get(image)\n        if faces:\n            face = faces[0]\n            cropped_face = crop_face(image, face.bbox.astype(int))\n            embedding = face.embedding\n        else:\n            cropped_face = image\n            embedding = np.random.randn(512)  # ì–¼êµ´ ê°ì§€ ì‹¤íŒ¨ ì‹œ ëœë¤ ë²¡í„° ì‚¬ìš©\n\n        if self.transform:\n            augmented = self.transform(image=cropped_face)\n            cropped_face = augmented[\"image\"]\n\n        embedding = torch.tensor(embedding, dtype=torch.float32)\n        label_group, label_member = self.labels[idx]\n        return embedding, torch.tensor(label_group, dtype=torch.long), torch.tensor(label_member, dtype=torch.long)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T01:47:41.334526Z","iopub.execute_input":"2025-03-12T01:47:41.334863Z","iopub.status.idle":"2025-03-12T01:47:41.350320Z","shell.execute_reply.started":"2025-03-12T01:47:41.334828Z","shell.execute_reply":"2025-03-12T01:47:41.349649Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# âœ… ë°ì´í„° ì¦ê°• ì„¤ì • (ì–¼êµ´ í¬ë¡­ í›„ ì ìš©)\ndata_transform = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.RandomBrightnessContrast(p=0.3),\n    A.MotionBlur(p=0.2),\n    A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.3, rotate_limit=20, p=0.5),\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T01:47:41.351126Z","iopub.execute_input":"2025-03-12T01:47:41.351389Z","iopub.status.idle":"2025-03-12T01:47:41.368327Z","shell.execute_reply.started":"2025-03-12T01:47:41.351341Z","shell.execute_reply":"2025-03-12T01:47:41.367631Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# âœ… ë°ì´í„° ë¡œë“œ\ndataset = FaceDataset(DATASET_DIR, transform=data_transform)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T01:47:41.370375Z","iopub.execute_input":"2025-03-12T01:47:41.370587Z","iopub.status.idle":"2025-03-12T01:47:41.404203Z","shell.execute_reply.started":"2025-03-12T01:47:41.370569Z","shell.execute_reply":"2025-03-12T01:47:41.403655Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# âœ… Train : Validation = 8 : 2 (Stratify ì ìš©)\nlabels = [group for group, _ in dataset.labels]\ntrain_indices, val_indices = train_test_split(range(len(dataset)), test_size=0.2, stratify=labels, random_state=42)\n\ntrain_dataset = torch.utils.data.Subset(dataset, train_indices)\nval_dataset = torch.utils.data.Subset(dataset, val_indices)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T01:47:41.405075Z","iopub.execute_input":"2025-03-12T01:47:41.405256Z","iopub.status.idle":"2025-03-12T01:47:41.414100Z","shell.execute_reply.started":"2025-03-12T01:47:41.405240Z","shell.execute_reply":"2025-03-12T01:47:41.413396Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# âœ… ê³„ì¸µì  ArcFace ë¶„ë¥˜ ëª¨ë¸\nclass HierarchicalArcFaceModel(nn.Module):\n    def __init__(self, embedding_size=512, num_groups=len(GROUPS), num_members=[len(members) for members in GROUPS.values()]):\n\n        super(HierarchicalArcFaceModel, self).__init__()\n        self.global_fc = nn.Sequential(\n            nn.Linear(embedding_size, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n        )\n        self.group_head = nn.Linear(512, num_groups)  # ê·¸ë£¹ ë¶„ë¥˜ í—¤ë“œ\n\n        self.member_heads = nn.ModuleList(\n            [nn.Linear(512, num_members[i]) for i in range(num_groups)]\n        )\n\n    def forward(self, x):\n        features = self.global_fc(x)\n        group_logits = self.group_head(features)  # ê·¸ë£¹ ì˜ˆì¸¡\n\n        predicted_group = torch.argmax(group_logits, dim=1)  # ì˜ˆì¸¡ëœ ê·¸ë£¹\n\n        batch_size = features.shape[0]\n        member_logits_padded = torch.zeros(batch_size, max([h.out_features for h in self.member_heads])).to(features.device)\n\n        for i in range(batch_size):\n            group_idx = predicted_group[i].item()\n            member_logits = self.member_heads[group_idx](features[i].unsqueeze(0))\n            member_logits_padded[i, :member_logits.shape[1]] = member_logits\n\n        return group_logits, member_logits_padded\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T01:47:41.414713Z","iopub.execute_input":"2025-03-12T01:47:41.414905Z","iopub.status.idle":"2025-03-12T01:47:41.431688Z","shell.execute_reply.started":"2025-03-12T01:47:41.414888Z","shell.execute_reply":"2025-03-12T01:47:41.430995Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"print(f\"ğŸ” ê·¸ë£¹ ê°œìˆ˜: {len(GROUPS)}\")\nprint(f\"ğŸ” ë©¤ë²„ ê°œìˆ˜ ë¦¬ìŠ¤íŠ¸: {[len(members) for members in GROUPS.values()]}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T01:47:41.432569Z","iopub.execute_input":"2025-03-12T01:47:41.432857Z","iopub.status.idle":"2025-03-12T01:47:41.446151Z","shell.execute_reply.started":"2025-03-12T01:47:41.432829Z","shell.execute_reply":"2025-03-12T01:47:41.445313Z"}},"outputs":[{"name":"stdout","text":"ğŸ” ê·¸ë£¹ ê°œìˆ˜: 6\nğŸ” ë©¤ë²„ ê°œìˆ˜ ë¦¬ìŠ¤íŠ¸: [2, 2, 4, 4, 2, 1]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# âœ… ë°ì´í„°ì…‹ ë¡œë“œ í›„ ë¼ë²¨ ê°’ í™•ì¸\nprint(f\"ğŸ” ê·¸ë£¹ ë¼ë²¨ ë²”ìœ„: {set([g for g, _ in dataset.labels])}\")  # ê·¸ë£¹ ë¼ë²¨ ìœ íš¨ ë²”ìœ„\nprint(f\"ğŸ” ë©¤ë²„ ë¼ë²¨ ë²”ìœ„: {set([m for _, m in dataset.labels])}\")  # ë©¤ë²„ ë¼ë²¨ ìœ íš¨ ë²”ìœ„\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T01:47:41.446990Z","iopub.execute_input":"2025-03-12T01:47:41.447256Z","iopub.status.idle":"2025-03-12T01:47:41.459782Z","shell.execute_reply.started":"2025-03-12T01:47:41.447235Z","shell.execute_reply":"2025-03-12T01:47:41.458987Z"}},"outputs":[{"name":"stdout","text":"ğŸ” ê·¸ë£¹ ë¼ë²¨ ë²”ìœ„: {0, 1, 2, 3, 4, 5}\nğŸ” ë©¤ë²„ ë¼ë²¨ ë²”ìœ„: {0, 1, 2, 3}\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# âœ… ê° ê·¸ë£¹ë³„ ë©¤ë²„ ê°œìˆ˜ í™•ì¸\ngroup_member_counts = {group: len(members) for group, members in GROUPS.items()}\nprint(f\"ğŸ” ê·¸ë£¹ë³„ ë©¤ë²„ ê°œìˆ˜: {group_member_counts}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T01:47:41.460518Z","iopub.execute_input":"2025-03-12T01:47:41.460793Z","iopub.status.idle":"2025-03-12T01:47:41.473276Z","shell.execute_reply.started":"2025-03-12T01:47:41.460766Z","shell.execute_reply":"2025-03-12T01:47:41.472442Z"}},"outputs":[{"name":"stdout","text":"ğŸ” ê·¸ë£¹ë³„ ë©¤ë²„ ê°œìˆ˜: {'EXO': 2, 'IVE': 2, 'NJZ': 4, 'RED': 4, 'SK': 2, 'UNKNOWN': 1}\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# âœ… ëª¨ë¸ ì´ˆê¸°í™”\nhierarchical_model = HierarchicalArcFaceModel().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(hierarchical_model.parameters(), lr=0.001, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T01:47:41.474195Z","iopub.execute_input":"2025-03-12T01:47:41.474528Z","iopub.status.idle":"2025-03-12T01:47:42.407229Z","shell.execute_reply.started":"2025-03-12T01:47:41.474508Z","shell.execute_reply":"2025-03-12T01:47:42.406318Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# âœ… í•™ìŠµ ì„¤ì •\nnum_epochs = 30\nbest_val_score = 0.0\npatience_counter = 0\nearly_stop_patience = 5\nMODEL_SAVE_PATH = \"/kaggle/working/2best_hierarchical_arcface.pth\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T01:47:42.408233Z","iopub.execute_input":"2025-03-12T01:47:42.408672Z","iopub.status.idle":"2025-03-12T01:47:42.412489Z","shell.execute_reply.started":"2025-03-12T01:47:42.408647Z","shell.execute_reply":"2025-03-12T01:47:42.411542Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import classification_report, confusion_matrix, average_precision_score, roc_auc_score, f1_score\n\ndef evaluate_model(model, data_loader):\n    model.eval()\n    all_group_preds, all_group_labels = [], []\n    all_member_preds, all_member_labels = [], []\n    all_group_probs, all_member_probs = [], []\n\n    num_groups = len(GROUPS)\n    num_members = sum(len(members) for members in GROUPS.values()) + 1\n\n    print(\"\\nğŸ” Running evaluation...\")  # âœ… í‰ê°€ ì‹œì‘ ë¡œê·¸\n\n    with torch.no_grad():\n        for embeddings, group_labels, member_labels in data_loader:\n            embeddings, group_labels, member_labels = embeddings.to(device), group_labels.to(device), member_labels.to(device)\n\n            group_logits, member_logits = model(embeddings)\n\n            # ğŸ”¥ í™•ë¥ ê°’ (Softmax ì ìš©)\n            group_probs = torch.softmax(group_logits, dim=1).cpu().numpy()\n            member_probs = torch.softmax(member_logits, dim=1).cpu().numpy()\n\n            predicted_group = np.argmax(group_probs, axis=1)\n            predicted_member = np.argmax(member_probs, axis=1)\n\n            all_group_preds.extend(predicted_group)\n            all_member_preds.extend(predicted_member)\n            all_group_labels.extend(group_labels.cpu().numpy())\n            all_member_labels.extend(member_labels.cpu().numpy())\n\n            all_group_probs.extend(group_probs)\n            all_member_probs.extend(member_probs)\n\n    # âœ… ë°ì´í„° ê²€ì¦ (ë¹„ì–´ìˆëŠ” ê²½ìš° ì˜ˆì™¸ì²˜ë¦¬)\n    if len(all_group_labels) == 0 or len(all_member_labels) == 0:\n        print(\"âš ï¸ No validation data available for evaluation.\")\n        return {\n            \"group_f1\": 0,\n            \"member_f1\": 0,\n            \"group_mAP\": 0,\n            \"member_mAP\": 0,\n            \"group_AUC\": 0,\n            \"member_AUC\": 0\n        }\n\n    # âœ… 1. ê·¸ë£¹ & ë©¤ë²„ë³„ F1 Score\n    group_f1 = f1_score(all_group_labels, all_group_preds, average=\"weighted\")\n    member_f1 = f1_score(all_member_labels, all_member_preds, average=\"weighted\")\n\n    # âœ… 2. mAP (mean Average Precision)\n    all_group_labels_bin = label_binarize(all_group_labels, classes=np.arange(num_groups))\n    all_member_labels_bin = label_binarize(all_member_labels, classes=np.arange(num_members))\n\n    map_score_group = average_precision_score(all_group_labels_bin, np.array(all_group_probs), average=\"macro\")\n    map_score_member = average_precision_score(all_member_labels_bin, np.array(all_member_probs), average=\"macro\")\n\n    # âœ… 3. ROC-AUC\n    roc_auc_group = roc_auc_score(all_group_labels_bin, np.array(all_group_probs), multi_class=\"ovr\")\n    roc_auc_member = roc_auc_score(all_member_labels_bin, np.array(all_member_probs), multi_class=\"ovr\")\n\n    return {\n        \"group_f1\": group_f1,\n        \"member_f1\": member_f1,\n        \"group_mAP\": map_score_group,\n        \"member_mAP\": map_score_member,\n        \"group_AUC\": roc_auc_group,\n        \"member_AUC\": roc_auc_member\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T01:47:42.413178Z","iopub.execute_input":"2025-03-12T01:47:42.413440Z","iopub.status.idle":"2025-03-12T01:47:42.424672Z","shell.execute_reply.started":"2025-03-12T01:47:42.413410Z","shell.execute_reply":"2025-03-12T01:47:42.423763Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# âœ… í•™ìŠµ ë£¨í”„ (ë§¤ ì—í­ë§ˆë‹¤ í‰ê°€ ìˆ˜í–‰)\nfor epoch in range(num_epochs):\n    hierarchical_model.train()\n    total_loss = 0.0\n    all_preds, all_labels = [], []\n\n    print(f\"\\nğŸ”„ Epoch {epoch+1}/{num_epochs} ì‹œì‘...\")  # âœ… ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€\n\n    for embeddings, group_labels, member_labels in tqdm(train_loader, desc=f\"ğŸ”„ Training Epoch {epoch+1}\"):\n        embeddings, group_labels, member_labels = embeddings.to(device), group_labels.to(device), member_labels.to(device)\n\n        group_pred, member_pred = hierarchical_model(embeddings)\n\n        group_loss = criterion(group_pred, group_labels)\n        member_loss = criterion(member_pred, member_labels)\n        loss = group_loss + member_loss\n\n        optimizer.zero_grad()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(hierarchical_model.parameters(), max_norm=1.0)\n        optimizer.step()\n\n        total_loss += loss.item()\n        all_preds.extend(torch.argmax(member_pred, dim=1).cpu().numpy())\n        all_labels.extend(member_labels.cpu().numpy())\n\n    train_f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n\n    # âœ… Validation ë‹¨ê³„ + í‰ê°€ ì§€í‘œ ì¶œë ¥\n    print(f\"\\nğŸ“Š Epoch {epoch+1} - Train Loss: {total_loss / len(train_loader):.4f} - Train F1: {train_f1:.4f}\")\n\n    # âœ… val_loaderê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸\n    if len(val_loader) == 0:\n        print(f\"\\nâš ï¸ Warning: val_loader is empty. Skipping evaluation.\")\n        continue  # í‰ê°€ ì—†ì´ ë‹¤ìŒ ì—í­ ì§„í–‰\n\n    print(\"\\nğŸ” Evaluating model...\")  # âœ… í‰ê°€ ì‹œì‘ ì•Œë¦¼\n    results = evaluate_model(hierarchical_model, val_loader)\n\n    # âœ… í‰ê°€ ì§€í‘œ ì¶œë ¥ (ë””ë²„ê¹… ë¡œê·¸)\n    print(f\"\\nğŸ“ˆ Evaluation Results:\")\n    print(f\"ğŸ¯ ê·¸ë£¹ F1 Score: {results['group_f1']:.4f}, mAP: {results['group_mAP']:.4f}, ROC-AUC: {results['group_AUC']:.4f}\")\n    print(f\"ğŸ¯ ë©¤ë²„ F1 Score: {results['member_f1']:.4f}, mAP: {results['member_mAP']:.4f}, ROC-AUC: {results['member_AUC']:.4f}\")\n\n    # âœ… ëª¨ë¸ ì €ì¥ (ìµœê³  ì„±ëŠ¥ ê¸°ì¤€)\n    if results[\"member_mAP\"] > best_val_score:\n        best_val_score = results[\"member_mAP\"]\n        patience_counter = 0\n        torch.save(hierarchical_model.state_dict(), MODEL_SAVE_PATH)\n        print(f\"\\nâœ… Best model saved at epoch {epoch+1} with Member mAP: {results['member_mAP']:.4f}\")\n    else:\n        patience_counter += 1\n\n    # âœ… Early Stopping ì ìš©\n    if patience_counter >= early_stop_patience:\n        print(\"\\nğŸ›‘ Early stopping activated! No improvement for 5 epochs.\")\n        break\n\n    scheduler.step()\n\nprint(f\"\\nâœ… ìµœì¢… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {MODEL_SAVE_PATH}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T01:47:42.425527Z","iopub.execute_input":"2025-03-12T01:47:42.425759Z","iopub.status.idle":"2025-03-12T03:31:29.092460Z","shell.execute_reply.started":"2025-03-12T01:47:42.425740Z","shell.execute_reply":"2025-03-12T03:31:29.087565Z"}},"outputs":[{"name":"stdout","text":"\nğŸ”„ Epoch 1/30 ì‹œì‘...\n","output_type":"stream"},{"name":"stderr","text":"ğŸ”„ Training Epoch 1:   0%|          | 0/97 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\nğŸ”„ Training Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [13:43<00:00,  8.49s/it]","output_type":"stream"},{"name":"stdout","text":"\nğŸ“Š Epoch 1 - Train Loss: 0.8238 - Train F1: 0.8465\n\nğŸ” Evaluating model...\n\nğŸ” Running evaluation...\n","output_type":"stream"},{"name":"stderr","text":"\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n","output_type":"stream"},{"name":"stdout","text":"\nğŸ“ˆ Evaluation Results:\nğŸ¯ ê·¸ë£¹ F1 Score: 0.8933, mAP: 0.8931, ROC-AUC: 0.9847\nğŸ¯ ë©¤ë²„ F1 Score: 0.9098, mAP: 0.9566, ROC-AUC: 0.9846\n\nâœ… Best model saved at epoch 1 with Member mAP: 0.9566\n\nğŸ”„ Epoch 2/30 ì‹œì‘...\n","output_type":"stream"},{"name":"stderr","text":"ğŸ”„ Training Epoch 2:   0%|          | 0/97 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\nğŸ”„ Training Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [13:45<00:00,  8.51s/it]","output_type":"stream"},{"name":"stdout","text":"\nğŸ“Š Epoch 2 - Train Loss: 0.5526 - Train F1: 0.8978\n\nğŸ” Evaluating model...\n\nğŸ” Running evaluation...\n","output_type":"stream"},{"name":"stderr","text":"\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n","output_type":"stream"},{"name":"stdout","text":"\nğŸ“ˆ Evaluation Results:\nğŸ¯ ê·¸ë£¹ F1 Score: 0.8936, mAP: 0.9107, ROC-AUC: 0.9873\nğŸ¯ ë©¤ë²„ F1 Score: 0.9136, mAP: 0.9500, ROC-AUC: 0.9829\n\nğŸ”„ Epoch 3/30 ì‹œì‘...\n","output_type":"stream"},{"name":"stderr","text":"ğŸ”„ Training Epoch 3:   0%|          | 0/97 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\nğŸ”„ Training Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [13:39<00:00,  8.45s/it]","output_type":"stream"},{"name":"stdout","text":"\nğŸ“Š Epoch 3 - Train Loss: 0.4905 - Train F1: 0.9006\n\nğŸ” Evaluating model...\n\nğŸ” Running evaluation...\n","output_type":"stream"},{"name":"stderr","text":"\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n","output_type":"stream"},{"name":"stdout","text":"\nğŸ“ˆ Evaluation Results:\nğŸ¯ ê·¸ë£¹ F1 Score: 0.8926, mAP: 0.9111, ROC-AUC: 0.9865\nğŸ¯ ë©¤ë²„ F1 Score: 0.9024, mAP: 0.9543, ROC-AUC: 0.9843\n\nğŸ”„ Epoch 4/30 ì‹œì‘...\n","output_type":"stream"},{"name":"stderr","text":"ğŸ”„ Training Epoch 4:   0%|          | 0/97 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\nğŸ”„ Training Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [13:31<00:00,  8.37s/it]","output_type":"stream"},{"name":"stdout","text":"\nğŸ“Š Epoch 4 - Train Loss: 0.4796 - Train F1: 0.9022\n\nğŸ” Evaluating model...\n\nğŸ” Running evaluation...\n","output_type":"stream"},{"name":"stderr","text":"\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n","output_type":"stream"},{"name":"stdout","text":"\nğŸ“ˆ Evaluation Results:\nğŸ¯ ê·¸ë£¹ F1 Score: 0.8964, mAP: 0.9204, ROC-AUC: 0.9876\nğŸ¯ ë©¤ë²„ F1 Score: 0.9148, mAP: 0.9533, ROC-AUC: 0.9845\n\nğŸ”„ Epoch 5/30 ì‹œì‘...\n","output_type":"stream"},{"name":"stderr","text":"ğŸ”„ Training Epoch 5:   0%|          | 0/97 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\nğŸ”„ Training Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [13:29<00:00,  8.35s/it]","output_type":"stream"},{"name":"stdout","text":"\nğŸ“Š Epoch 5 - Train Loss: 0.4657 - Train F1: 0.9016\n\nğŸ” Evaluating model...\n\nğŸ” Running evaluation...\n","output_type":"stream"},{"name":"stderr","text":"\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n","output_type":"stream"},{"name":"stdout","text":"\nğŸ“ˆ Evaluation Results:\nğŸ¯ ê·¸ë£¹ F1 Score: 0.9082, mAP: 0.9278, ROC-AUC: 0.9889\nğŸ¯ ë©¤ë²„ F1 Score: 0.9136, mAP: 0.9530, ROC-AUC: 0.9841\n\nğŸ”„ Epoch 6/30 ì‹œì‘...\n","output_type":"stream"},{"name":"stderr","text":"ğŸ”„ Training Epoch 6:   0%|          | 0/97 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\nğŸ”„ Training Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [13:25<00:00,  8.31s/it]","output_type":"stream"},{"name":"stdout","text":"\nğŸ“Š Epoch 6 - Train Loss: 0.4548 - Train F1: 0.9106\n\nğŸ” Evaluating model...\n\nğŸ” Running evaluation...\n","output_type":"stream"},{"name":"stderr","text":"\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n","output_type":"stream"},{"name":"stdout","text":"\nğŸ“ˆ Evaluation Results:\nğŸ¯ ê·¸ë£¹ F1 Score: 0.8928, mAP: 0.9188, ROC-AUC: 0.9879\nğŸ¯ ë©¤ë²„ F1 Score: 0.9149, mAP: 0.9570, ROC-AUC: 0.9854\n\nâœ… Best model saved at epoch 6 with Member mAP: 0.9570\n\nğŸ”„ Epoch 7/30 ì‹œì‘...\n","output_type":"stream"},{"name":"stderr","text":"ğŸ”„ Training Epoch 7:   0%|          | 0/97 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\nğŸ”„ Training Epoch 7:   8%|â–Š         | 8/97 [01:18<14:32,  9.80s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-05ea70af8443>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nğŸ”„ Epoch {epoch+1}/{num_epochs} ì‹œì‘...\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# âœ… ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmember_labels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"ğŸ”„ Training Epoch {epoch+1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmember_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmember_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1403\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1241\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1244\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":17}]}